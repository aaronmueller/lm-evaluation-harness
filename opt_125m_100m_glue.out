]P02d2d2d]P1f2777a]P299cc99]P3ffcc66]P46699cc]P5cc99cc]P666cccc]P7d3d0c8]P8747369]P9f2777a]Pa99cc99]Pbffcc66]Pc6699cc]Pdcc99cc]Pe66cccc]Pff2f0ecactivate does not accept more than one argument:
['test/babyLM_100M/', 'decoder', 'glue', '16']

Traceback (most recent call last):
  File "/export/c09/amueller/lm-evaluation-harness/babylm_eval.py", line 34, in <module>
    eval_model = lm_eval.get_model(MODEL_TYPE_REMAP[args.model_type],
  File "/export/c09/amueller/lm-evaluation-harness/lm_eval/models/__init__.py", line 42, in get_model
    return model_api_class(**model_kwargs)
  File "/export/c09/amueller/lm-evaluation-harness/lm_eval/models/huggingface.py", line 190, in __init__
    self.model.to(self._device)
  File "/home/amueller/miniconda3/envs/lm-eval/lib/python3.10/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/amueller/miniconda3/envs/lm-eval/lib/python3.10/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/amueller/miniconda3/envs/lm-eval/lib/python3.10/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/amueller/miniconda3/envs/lm-eval/lib/python3.10/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/amueller/miniconda3/envs/lm-eval/lib/python3.10/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/amueller/miniconda3/envs/lm-eval/lib/python3.10/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: all CUDA-capable devices are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
